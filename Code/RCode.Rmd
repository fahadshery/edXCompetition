# R Code for edX Competition on *"Analytics Edge"* DataScience Course
==================================================================

#### Author: Fahad Usman
#### Date: 21 April 2014

## The Problem Statement: Learn what predicts happiness by using informal polling questions. 

What predicts happiness? In this competition, you'll be using data from Show of Hands, an informal polling platform for use on mobile devices and the web, to see what aspects and characteristics of people's lives predict happiness.

Show of Hands has been downloaded over 300,000 times across Apple and Android app stores, and users have cast more than 75 million votes. In this problem, we'll use data from thousands of users and one hundred different questions to see which responses predict happiness.

## Acknowledgements

This competition is brought to you by 15.071x, edX, and Show of Hands.

## File descriptions

Here is a description of the files you have been provided for this competition:

- **train.csv** - the training set of data that you should use to build your models
- **test.csv**  - the test set that you will be evaluated on. It contains all of the independent variables, but not the dependent variable.
- **sampleSubmission.csv** - a sample submission file in the correct format.
- **Questions.pdf** - the question test corresponding to each of the question codes, as well as the possible answers.

## Data fields

- **UserID** - an anonymous id unique to a given user
- **YOB** - the year of birth of the user
- **Gender** - the gender of the user, either Male, Female, or not provided
- **Income** - the household income of the user. Either not provided, or one of "under $25,000", "$25,001 - $50,000", "$50,000 - $74,999", "$75,000 - $100,000", "$100,001 - $150,000", or "over $150,000".
- **HouseholdStatus** - the household status of the user. Either not provided, or one of "Domestic Partners (no kids)", "Domestic Partners (w/kids)", "Married (no kids)", "Married (w/kids)", "Single (no kids)", or "Single (w/kids)".
- **EducationLevel** - the education level of the user. Either not provided, or one of "Current K-12", "High School Diploma", "Current Undergraduate", "Associate's Degree", "Bachelor's Degree", "Master's Degree", or "Doctoral Degree".
- **Party** - the political party of the user. Either not provided, or one of "Democrat", "Republican", "Independent", "Libertarian", or "Other".
- **Happy** - a binary variable, with value 1 if the user said they were happy, and with value 0 if the user said that were neutral or not happy. This is the variable you are trying to predict.
- Q124742, Q124122, . . . , Q96024 - 101 different questions that the users were asked on Show of Hands. If the user didn't answer the question, there is a blank. For information about the question text and possible answers, see the file Questions.pdf.
- **votes** - the total number of questions that the user responded to, out of the 101 questions included in the data set (this count does not include the happiness question).


Let's begin by reading in the train file:

```{r, include=FALSE}
library(markdown)
library(knitr)
```

```{r}
happinessTrain = read.csv("C:/Users/Fahad/Documents/R Projects/edXCompetition/Data/train.csv")
```

Always check the data structure first, So we can take a look at the structure of our new data frame by using the str and summary functions:

```{r}
str(happinessTrain)
str(happinessTrain$Q124742)
summary(happinessTrain)
summary(happinessTrain$Q124742)
View(happinessTrain)
summary(happinessTrain$Q114386)
summary(happinessTrain$Q115899)
```

So we have 4619 observations and 110 columns/variables.

Lets check how many are happy and how many are not in the training set:

```{r}

table(happinessTrain$Happy)
prop.table(table(happinessTrain$Happy))

```

56.4% people are happy and 43.6% are not in the training set.

Let's check the male/female proportions now:

```{r}
# proportion of men, women and not answered in the train set
prop.table(table(happinessTrain$Gender))
```

Here we have 52.6% male, 35.7% female and 11.6% not answered population in the training set.

Let's check what proportion of these people are happy by:

```{r}
prop.table(table(happinessTrain$Gender, happinessTrain$Happy))

```

Well that's not very clean, the proportion table command by default takes each entry in the table and divides by the total number of passengers. What we want to see is the row-wise proportion, ie, the proportion of each sex that is happy, as separate groups. So we need to tell the command to give us proportions in the 1st dimension which stands for the rows (using '2' instead would give you column proportions):

```{r}
prop.table(table(happinessTrain$Gender, happinessTrain$Happy), 1)

```
This now shows that 45.7% of all the females are not happy and 54.2% are happy. Similarly, 57% overall male population  is happy and 43% is not happy. This shows that male population is a bit more happier than the female population in the train dataset.

Let's look into the income variable now (just following intution tbh!):

```{r}
prop.table(table(happinessTrain$Gender, happinessTrain$Income),1)

```
This doesn't tell much...

## Baseline Predictions
we can compare our predictions to the baseline method of predicting the average outcome for all data points. 

In a classification problem, a standard baseline method is to just predict the most frequent outcome for all observations. So to check the common outcome we can use the table command:

```{r}

table(happinessTrain$Happy)

```


Since happiness is more common than not happy, in this case, we would predict that everyone is happy.

```{r}
2604/nrow(happinessTrain)

```

If we did this, we would get 2604 out of the 4619 observations correct, or have an accuracy of about 56.4%. This is what we'll try to beat with our logistic regression model.




