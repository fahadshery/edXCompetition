# R Code for edX Competition on *"Analytics Edge"* DataScience Course
==================================================================

#### Author: Fahad Usman
#### Date: 21 April 2014

## The Problem Statement: Learn what predicts happiness by using informal polling questions. 

What predicts happiness? In this competition, you'll be using data from Show of Hands, an informal polling platform for use on mobile devices and the web, to see what aspects and characteristics of people's lives predict happiness.

Show of Hands has been downloaded over 300,000 times across Apple and Android app stores, and users have cast more than 75 million votes. In this problem, we'll use data from thousands of users and one hundred different questions to see which responses predict happiness.

## Acknowledgements

This competition is brought to you by 15.071x, edX, and Show of Hands.

## File descriptions

Here is a description of the files you have been provided for this competition:

- **train.csv** - the training set of data that you should use to build your models
- **test.csv**  - the test set that you will be evaluated on. It contains all of the independent variables, but not the dependent variable.
- **sampleSubmission.csv** - a sample submission file in the correct format.
- **Questions.pdf** - the question test corresponding to each of the question codes, as well as the possible answers.

## Data fields

- **UserID** - an anonymous id unique to a given user
- **YOB** - the year of birth of the user
- **Gender** - the gender of the user, either Male, Female, or not provided
- **Income** - the household income of the user. Either not provided, or one of "under $25,000", "$25,001 - $50,000", "$50,000 - $74,999", "$75,000 - $100,000", "$100,001 - $150,000", or "over $150,000".
- **HouseholdStatus** - the household status of the user. Either not provided, or one of "Domestic Partners (no kids)", "Domestic Partners (w/kids)", "Married (no kids)", "Married (w/kids)", "Single (no kids)", or "Single (w/kids)".
- **EducationLevel** - the education level of the user. Either not provided, or one of "Current K-12", "High School Diploma", "Current Undergraduate", "Associate's Degree", "Bachelor's Degree", "Master's Degree", or "Doctoral Degree".
- **Party** - the political party of the user. Either not provided, or one of "Democrat", "Republican", "Independent", "Libertarian", or "Other".
- **Happy** - a binary variable, with value 1 if the user said they were happy, and with value 0 if the user said that were neutral or not happy. This is the variable you are trying to predict.
- Q124742, Q124122, . . . , Q96024 - 101 different questions that the users were asked on Show of Hands. If the user didn't answer the question, there is a blank. For information about the question text and possible answers, see the file Questions.pdf.
- **votes** - the total number of questions that the user responded to, out of the 101 questions included in the data set (this count does not include the happiness question).


Let's begin by reading in the train file:

```{r, include=FALSE}
library(markdown)
library(knitr)
```

```{r}
happinessTrain = read.csv("C:/Users/Fahad/Documents/R Projects/edXCompetition/Data/train.csv")
happinessTest = read.csv("C:/Users/Fahad/Documents/R Projects/edXCompetition/Data/test.csv")

```

Always check the data structure first, So we can take a look at the structure of our new data frame by using the str and summary functions:

```{r}
str(happinessTrain)
str(happinessTrain$Q124742)
summary(happinessTrain)
summary(happinessTrain$Q124742)
View(happinessTrain)
summary(happinessTrain$Q114386)
summary(happinessTrain$Q115899)
```

So we have 4619 observations and 110 columns/variables.

Lets check how many are happy and how many are not in the training set:

```{r}

table(happinessTrain$Happy)
prop.table(table(happinessTrain$Happy))

```

56.4% people are happy and 43.6% are not in the training set.

Let's check the male/female proportions now:

```{r}
# proportion of men, women and not answered in the train set
prop.table(table(happinessTrain$Gender))
```

Here we have 52.6% male, 35.7% female and 11.6% not answered population in the training set.

Let's check what proportion of these people are happy by the following command:

```{r}
prop.table(table(happinessTrain$Gender, happinessTrain$Happy))

```

Well that's not very clean, the proportion table command by default takes each entry in the table and divides by the total number of passengers. What we want to see is the row-wise proportion, ie, the proportion of each sex that is happy, as separate groups. So we need to tell the command to give us proportions in the 1st dimension which stands for the rows (using '2' instead would give you column proportions):

```{r}
prop.table(table(happinessTrain$Gender, happinessTrain$Happy), 1)

```
OR you can use tapply function which can show what proportion of Gender population is happy by:

```{r}
tapply(happinessTrain$Happy, happinessTrain$Gender, mean)
```

This now shows that 45.7% of all the females are not happy and 54.2% are happy. Similarly, 57% overall male population  is happy and 43% is not happy. This shows that male population is a bit more happier than the female population and finally about 60% people who didn't supplied Gender information in the train dataset are happy and 40% are not.

Let's look into the income variable now (just following intuition tbh!):

```{r}
prop.table(table(happinessTrain$Happy, happinessTrain$Income),1)

```
Interestingly, 26% of the people earning between $100,001 - $150,000 are happy and equally amount of people are not happy...Almost similar results are found in other Income ranges...So this doesn't tell much really if the income is related with the happiness...


## Baseline Predictions
we can compare our predictions to the baseline method of predicting the average/mean outcome for all data points. 

In a classification problem, a standard baseline method is to just predict the most frequent outcome for all observations. So to check the common outcome we can use the table command:

```{r}

table(happinessTrain$Happy)

```

Since happiness is more common than not happy, in this case, we would predict that everyone is happy.

```{r}
2604/nrow(happinessTrain)

```

If we did this, we would get 2604 out of the 4619 observations correct, or have an accuracy of about 56.4%. This is what we'll try to beat with our first linear regression model.

## Linear Regression

Linear regression discards observations with missing data, so we will remove all such observations from the training and testing sets. Later, we will learn about imputation, which deals with missing data by filling in missing values with plausible information.

The following commands can be used to remove observations with any missing value from happinessTrain and happinessTest:

```{r}
hap.Train.Without.Missing.Values = na.omit(happinessTrain)
hap.Test.Without.Missing.Values = na.omit(happinessTest)
```

check the structure now:

```{r}
str(hap.Train.Without.Missing.Values)
summary(hap.Train.Without.Missing.Values)
```
Let's build our first Linear Regression model using all variables except the UserID and YOB:

```{r}

LinearRegModel = lm(Happy ~ . -UserID -YOB -votes,data=hap.Train.Without.Missing.Values)
summary(LinearRegModel)

```

The training-set RMSE can be computed by first computing the SSE:
```{r}
SSE = sum(LinearRegModel$residuals^2)
```
and then dividing by the number of observations and taking the square root:
```{r}
RMSE = sqrt(SSE / nrow(hap.Train.Without.Missing.Values))
```
A alternative way of getting this answer would be with the following command:
```{r}
sqrt(mean(LinearRegModel$residuals^2)) 
```
## Automatically Building the Model

We have many variables in this problem, and many are insignificant...R provides a function, **step**, that will automate the procedure of trying different combinations of variables to find a good compromise of model simplicity and R2. This trade-off is formalised by the Akaike information criterion (AIC) - it can be informally thought of as the quality of the model with a penalty for the number of variables in the model.

The step function has one argument - the name of the initial model. It returns a simplified model. Use the step function in R to derive a new model, with the full model as the initial model.

```{r}
LinearRegStepModel = step(LinearRegModel)
summary(LinearRegStepModel)
```

It is interesting to note that the step function does not address the collinearity of the variables, except that adding highly correlated variables will not improve the R2 significantly. The consequence of this is that the step function will not necessarily produce a very interpretable model - just a model that has balanced quality and simplicity for a particular weighting of quality and simplicity (AIC).

